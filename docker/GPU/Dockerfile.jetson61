# syntax=docker/dockerfile:1.7-labs
# use buildkit

FROM nvcr.io/nvidia/l4t-jetpack:r36.4.0

# This docker installs:
    # - onedl-mim
    # - onedl-mmcv and onedl-mmengine
    # - ppl.cv
    # - onedl-mmdeploy [cuda;cpu, ort;trt, mmpretrain;mmseg;mmdet;mmrotate]

ARG PPLCV_VERSION=0.8.0

ARG MMCV_VERSION=">=2.3.0"
ARG MMENGINE_VERSION=">=0.10.8"

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_BREAK_SYSTEM_PACKAGES=1

# and install libs
ADD https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/arm64/cuda-keyring_1.1-1_all.deb .
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked,id=apt-cache \
    --mount=type=cache,target=/var/lib/apt,sharing=locked,id=apt-lib \
    dpkg -i cuda-keyring_1.1-1_all.deb && apt-get update \
    && apt-get install -y --no-install-recommends \
    git python3-pip libopenmpi-dev libopenblas-dev libomp-dev libcusparselt0 libcusparselt-dev \
    curl libspdlog-dev vim pkg-config cmake cudss \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# install torch, torchvision, onnx
# https://pypi.jetson-ai-lab.dev/
# TODO: copy to our own servers?
RUN --mount=type=cache,target=/root/.cache/pip,id=pip \
    python3 -m pip install --upgrade pip; python3 -m pip install --no-cache \
    https://pypi.jetson-ai-lab.io/jp6/cu126/+f/62a/1beee9f2f1470/torch-2.8.0-cp310-cp310-linux_aarch64.whl#sha256=62a1beee9f2f147076a974d2942c90060c12771c94740830327cae705b2595fc \
    https://pypi.jetson-ai-lab.io/jp6/cu126/+f/907/c4c1933789645/torchvision-0.23.0-cp310-cp310-linux_aarch64.whl#sha256=907c4c1933789645ebb20dd9181d40f8647978e6bd30086ae7b01febb937d2d1 \
    https://pypi.jetson-ai-lab.io/jp6/cu126/+f/4eb/e6a8902dc7708/onnxruntime_gpu-1.23.0-cp310-cp310-linux_aarch64.whl#sha256=4ebe6a8902dc7708434b2e1541b3fe629ebf434e16ab5537d1d6a622b42c622b

# install and build pplc.cv
WORKDIR /workspace
RUN git clone -b v${PPLCV_VERSION} --single-branch https://github.com/VBTI-development/ppl.cv.git &&\
    cd ppl.cv &&\
    ./build.sh cuda
ENV PPLCV_DIR=/workspace/ppl.cv

WORKDIR /workspace
# install onedl-mmcv
RUN --mount=type=cache,target=/root/.cache/pip,id=pip \
    python3 -m pip install --no-cache "onedl-mmcv${MMCV_VERSION}" "onedl-mmengine${MMENGINE_VERSION}"  --only-binary=onedl-mmcv -f https://mmwheels.onedl.ai/jp61-torch280/

# ### install mmdeploy
ENV TENSORRT_DIR=/workspace/tensorrt
WORKDIR /workspace/

ENV BACKUP_LD_LIBRARY_PATH=$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH=/usr/local/cuda/compat/lib.real/:$LD_LIBRARY_PATH

COPY . /workspace/onedl-mmdeploy
RUN cd onedl-mmdeploy && \
    mkdir -p build && cd build &&\
    cmake .. \
        -DMMDEPLOY_BUILD_SDK=ON \
        -DMMDEPLOY_BUILD_SDK_PYTHON_API=ON \
        -DMMDEPLOY_BUILD_EXAMPLES=OFF \
        -DMMDEPLOY_TARGET_DEVICES="cuda;cpu" \
        -DMMDEPLOY_TARGET_BACKENDS="trt" \
        -DMMDEPLOY_CODEBASES="mmpretrain;mmdet;mmseg;mmrotate" \
        -Dpplcv_DIR=${PPLCV_DIR}/cuda-build/install/lib/cmake/ppl &&\
    make -j$(nproc) && make install &&\
    export SPDLOG_LEVEL=debug &&\
    echo "Built MMDeploy version for Jetpack 6.1 devices successfully!" && \
    cd ../ &&\
    python3 -m mim install --config-settings editable_mode=compat -e .

LABEL org.opencontainers.image.source=https://github.com/vbti-development/onedl-mmdeploy
LABEL org.opencontainers.image.description="OneDL MMDeploy Docker Image with Jetpack 6.1 support"
LABEL org.opencontainers.image.licenses=Apache-2.0
LABEL org.opencontainers.image.vendor="VBTI Products BV"
